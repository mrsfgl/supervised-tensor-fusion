{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "34dfee18d5f4a96df9a8fcc719c91cf50e8ed50de2aa108bf45cd20982063274"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Visual Oddball Stimulus Trail Type Classification #\n",
    "\n",
    "We use tensor-based Discriminant analysis from Li, Q., & Schonfeld, D. (2014). Multilinear discriminant analysis for higher-order tensor data classification. IEEE transactions on pattern analysis and machine intelligence, 36(12), 2524-2537. to conduct a classification analysis. The data is the EEG part from a multimodal neuroimaging experiment. This task is a comparison to our multimodal Coupled Tensor Classification "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from hdf5storage import loadmat\n",
    "import MDA \n",
    "from classification_tools import classification_metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "df = loadmat('EEG_Visual_df.mat')['Xdata']\n",
    "y = loadmat('EEG_Visual_label.mat')['ylabel']\n",
    "y = y - 1   # convert labels to 0-1\n",
    "\n",
    "# Convert data to list as it is required by our function application\n",
    "Xdata = [df[:, :, :, j] for j in range(90)]\n",
    "y = y.reshape(90).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "90 90\n"
     ]
    }
   ],
   "source": [
    "print(len(Xdata), len(y))"
   ]
  },
  {
   "source": [
    "Perfrom stratified 9 folds corss validation to evaluate model performance. The percentages of samples for each class are the same in each fold."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorly.tenalg import multi_mode_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(999)\n",
    "acc_CMDA, prec_CMDA, rec_CMDA, spec_CMDA = [], [], [], []\n",
    "acc_DGTDA, prec_DGTDA, rec_DGTDA, spec_DGTDA = [], [], [], []\n",
    "skf = StratifiedKFold(n_splits= 9)\n",
    "for train_indx, test_indx in skf.split(np.zeros(len(Xdata)), y):\n",
    "    Xtrain = [Xdata[i] for i in train_indx]\n",
    "    Xtest = [Xdata[j] for j in test_indx]\n",
    "    ytrain = [y[i] for i in train_indx]\n",
    "    ytest = [y[j] for j in test_indx]\n",
    "    U_CMDA = MDA.CMDA(Xtrain, ytrain)\n",
    "    U_DGTDA = MDA.DGTDA(Xtrain, ytrain)\n",
    "    Xtrain_CMDA = [multi_mode_dot(x, U_CMDA) for x in Xtrain]\n",
    "    Xtrain_DGTDA = [multi_mode_dot(x, U_DGTDA) for x in Xtrain]\n",
    "    Xtest_CMDA = [multi_mode_dot(z, U_CMDA) for z in Xtest]\n",
    "    Xtest_DGTDA = [multi_mode_dot(z, U_DGTDA) for z in Xtest]\n",
    "    y_CMDA = MDA.Tensor_NN(Xtrain_CMDA, ytrain, Xtest_CMDA, 1)\n",
    "    y_DGTDA = MDA.Tensor_NN(Xtrain_DGTDA, ytrain, Xtest_DGTDA, 1)\n",
    "    a, b, c, d = classification_metrics(ytest, y_CMDA)\n",
    "    acc_CMDA.append(a)\n",
    "    prec_CMDA.append(b)\n",
    "    rec_CMDA.append(c)\n",
    "    spec_CMDA.append(d)\n",
    "    a, b, c, d = classification_metrics(ytest, y_DGTDA)\n",
    "    acc_DGTDA.append(a)\n",
    "    prec_DGTDA.append(b)\n",
    "    rec_DGTDA.append(c)\n",
    "    spec_DGTDA.append(d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "Display Classification result for CMDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5666666666666667 0.15634719199411432\n0.5630511463844797 0.1399303913338515\n0.7111111111111111 0.1911627837120584\n0.4222222222222223 0.23934065809486685\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(acc_CMDA), np.std(acc_CMDA))\n",
    "print(np.mean(prec_CMDA), np.std(prec_CMDA))\n",
    "print(np.mean(rec_CMDA), np.std(rec_CMDA))\n",
    "print(np.mean(spec_CMDA), np.std(spec_CMDA))"
   ]
  },
  {
   "source": [
    "Display result for DGTDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5444444444444445 0.10657403385139375\n0.5264550264550265 0.106529369099707\n0.6222222222222222 0.21998877636914813\n0.4666666666666667 0.1632993161855452\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(acc_DGTDA), np.std(acc_DGTDA))\n",
    "print(np.mean(prec_DGTDA), np.std(prec_DGTDA))\n",
    "print(np.mean(rec_DGTDA), np.std(rec_DGTDA))\n",
    "print(np.mean(spec_DGTDA), np.std(spec_DGTDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}